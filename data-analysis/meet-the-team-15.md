---
description: >-
  The dataset for this Sprint is the Ultimate 25k+ Matches Football Database. It
  is a large dataset, which will provide your with a lot of opportunities both
  for statistical inference and for prediction
---

# ðŸ‘¨ðŸ’» CAPSTONE PROJECT

### Data <a href="#data" id="data"></a>

**Ultimate 25k+ Matches Football Database**

![](https://images.unsplash.com/photo-1489944440615-453fc2b6a9a9?ixlib=rb-1.2.1\&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8\&auto=format\&fit=crop\&w=1482\&q=80)

Imagine that you are a data scientist working in a sports betting company. The business executives in your company after some initial analysis (they watched this video [Understanding European Soccer in Four Simple Steps: A Guide For Americans](https://www.youtube.com/watch?v=FZ4i3KX2CW4)) identified betting on soccer (European football) as an potential new business opportunity. The problem is that your company doesn't know a lot about soccer (European football). Your manager asked you to analyse this dataset and see if you can provide anything that could give us a competitive advantage in the attempt to start strong in the new endevor. She has provided your with some questions, which she suggests are a good starting point for your analysis.

* Which leagues are in which countries?
* Which leagues score the most/fewest goals?
* Who are the top scorers in each team and league?
* Is there such a thing as home advantage?
* Can we predict how many goals each team will score in each match?
* Can we predict which team will win the match?

The link to the [Kaggle dataset is here](https://www.kaggle.com/prajitdatta/ultimate-25k-matches-football-database-european).

### Requirements <a href="#requirements" id="requirements"></a>

* Perform data cleaning and feature engineering. Work with features - handle missing data if needed, use SQL and Pandas functions to create other additional features.
* Perform exploratory data analysis. Describe the data with basic statistical parameters - mean, median, quantiles, etc. Use parameters that give you the most important statistical insights of the data. Grouping the data and analyzing the groups - using SQL or Pandas aggregate methods. Visualize the data - you can use line, scatter, histogram plots, density plots, regplots, etc.
* Perform statistical inference. Raise and test statistical hypotheses. Set appropriate significance levels and create confidence intervals for the variables of interest.
* Train linear machine learning models and use them for forecasting. Use cross validation, information criteria, and/or other methods to specify your models correctly. Choose and use appropriate metrics to measure your models' performance.
* Create a Google Data Studio dashboard with at least three different types of charts.
* Provide clear explanations in your notebook. Your explanations should inform the reader what you are trying to achieve, what results did you get, and what these results mean.
* Present the project - the data, methods, and results.
* Provide suggestions about how your analysis can be improved.

### Bonus Challenges <a href="#bonus-challenges" id="bonus-challenges"></a>

As a data scientists you will spend significant amount of your time learning new things. Sometimes you will do that for fun, but most of the time you will have an urgent problem and you will need to quickly learn some new skill to be able to solve it. It is very important to gradually build this skill - it is extremely valuable for all data scientists. The bonus challenges are designed to simulate these types of situations. These challenges require you to do something that we haven't covered in the course yet. Instead of trying to do all of the bonus challenges, concentrate on just one or two and do them well. All of the bonus challenges are optional - no points will be deducted if you skip them.

* Try dimensionality reduction algorithm (e.g. PCA, t-SNE, Autoencoder).
* Try clustering your data.
* Try a nonlinear machine learning model to explain relationships between features and predict new values.
