---
description: >-
  You will train and deploy a machine learning model on the Stroke Prediction
  Dataset.
---

# üêì Gradient Boosted Trees & Feature Engineering

### Requirements <a href="#requirements" id="requirements"></a>

* Download the data from [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset).
* Perform exploratory data analysis. This should include creating statistical summaries and charts, testing for anomalies, and checking for correlations and other relations between variables and other EDA elements.
* Perform statistical inference. This should include defining the target population, forming multiple statistical hypotheses and constructing confidence intervals, setting the significance levels, and conducting z or t-tests for these hypotheses.
* Apply various machine learning models to predict the "stroke" column using all other features. This should include hyperparameter tuning, model ensembling, the analysis of model selection, and other methods. Suggestion: you might want to investigate how to use (scikit-learn pipelines)\[[https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\]](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html]) to make your training pipelines more robust.
* Deploy the machine learning model. Choose the best performing model and deploy it. You are free to choose any deployment option that you like - you can deploy your model in a container (on your computer or on a server), do a serverless deployment on the cloud, or even deploy and serve it on the browser as a web app.
* Provide clear explanations in your notebook. Your explanations should inform the reader what you are trying to achieve, what results did you get, and what these results mean.
* Provide suggestions about how your analysis can be improved.
